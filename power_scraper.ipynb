{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Power scraper\n",
    "The power scraper's goal is to scrape hourly power production averages from [ENTSO-E](https://en.wikipedia.org/wiki/European_Network_of_Transmission_System_Operators_for_Electricity)'s [API](https://transparency.entsoe.eu/content/static_content/Static%20content/web%20api/Guide.html), and put it into a pandas dataframe for smoother analysis going onwards."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From [this PDF (page 13/16)](https://transparency.entsoe.eu/content/static_content/download?path=/Static%20content/web%20api/RestfulAPI_IG.pdf) I've learned that we are looking to scrape a _Document Type_ named _A73_ and described as _Actual generation output per generation unit_. This document type is also coupled with a _Process Type_ named _A16_ and described as _Realised_ that I believe reference that it relates to actual generation as compared to for example forcasted generation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "- [ENTSO-E API implementation guide](https://transparency.entsoe.eu/content/static_content/download?path=/Static%20content/web%20api/RestfulAPI_IG.pdf)\n",
    "- [ENTSO-E API web guide](https://transparency.entsoe.eu/content/static_content/Static%20content/web%20api/Guide.html)\n",
    "- [EnergieID/entsoe-py](https://github.com/EnergieID/entsoe-py): A python client for working against the ENTSO-E API\n",
    "- [ElectricityMap's use of ENTSO-E's API](https://github.com/tmrowco/electricitymap-contrib/blob/master/parsers/ENTSOE.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup to run code\n",
    "In order for you to be able to use this code, you need an API Token for accessing the ENTSO-E API. For instructions on how to get one, see [their documentation about it](https://transparency.entsoe.eu/content/static_content/Static%20content/web%20api/Guide.html#_authentication_and_authorisation).\n",
    "\n",
    "This is what you need to do summarized:\n",
    "\n",
    "1. Create an account on the [Transparency Platform (TP)](https://transparency.entsoe.eu/).\n",
    "2. Send an email to transparency@entsoe.eu with `Restful API access` in the subject line. Indicate the email address you entered during registration in the email body.\n",
    "3. Await a response and inspect [your account settings](https://transparency.entsoe.eu/usrm/user/myAccountSettings) where a _Web Api Security Token_ should now be available.\n",
    "4. Write your API_TOKEN to the `.env` file or set manually update your environment variable `API_TOKEN` for use by the scripts below. The file should contain one line of text formatted like this:\n",
    "\n",
    "   ```\n",
    "   API_TOKEN=your-api-token-here\n",
    "   ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load's API_TOKEN from the .env file which is .gitignore'd\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code strategy\n",
    "We rely heavily on the `EntsoePandasClient` of the `entsoe` Python library, and its [query_generation_per_plant function](https://github.com/EnergieID/entsoe-py/blob/e620357ad6ea0ddd217d4cff61eed18e8461f584/entsoe/entsoe.py#L905). Iterating over it for each country, and using a time interval from the beginning of the API's creation, to now.\n",
    "\n",
    "Caching web requests, saving completed country downloads, and progressbars is the glue that takes us all the way.\n",
    "\n",
    "### About web request caching\n",
    "We should avoid making web request to the API in order to avoid paing a cost of time and potentially getting rate limited or banned. To do this we can try to cache as much requests we make as possible, as the data isn't supposed to change anyhow.\n",
    "\n",
    "Consider us using the `query_generation_per_plant` function and passing a timespan of a week. I've learned it will make seven requests to the ENTSO-E API, one per day, because it is simply a restriction on their API. If we now specify overlapping days in a later request, these days will be cached and we will only probe the actual API with those that had not already been requested. All of this is done by us importing [requests-cache](https://github.com/reclosedev/requests-cache) and saying we want to use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a cache so we don't ask the same thing twice\n",
    "# this is what is stored in the entso-e.sqlite database file\n",
    "import requests_cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Progress bars for sanity\n",
    "When working with long running jobs, having a progress bar is very useful. The tqdm library provides such functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# progress bars beauty\n",
    "# https://github.com/tqdm/tqdm#ipythonjupyter-integration\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modifications to entsoe library\n",
    "I made some modification to not abort scraping if a exception about no available data was thrown for an individual day. This changes are part of a fork on https://github.com/consideRatio/entsoe-py."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code improvements\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping time estimates\n",
    "It took 130 seconds to get data about Sweden for a month, or about five seconds per day. The dates to investigate range from 2015-01-05 onwards, which is about five years, which is about 60 months. 60 months * 130 seconds / month = 130 minutes for one country. With 42 different country entries we can choose from in the `entsoe.mappings.DOMAIN_MAPPINGS`, we have something that needs to run for about 130 minutes * 42 ~= 3.8 days."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from entsoe import EntsoePandasClient\n",
    "from entsoe.mappings import DOMAIN_MAPPINGS\n",
    "import entsoe.misc\n",
    "\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_country_data(country_code, start, end):\n",
    "    \"\"\"\n",
    "    Returns a pandas dataframe containing the specified country's\n",
    "    production units and how much energy they produced that hour\n",
    "    with a hourly resolution.\n",
    "    \"\"\"\n",
    "    # To help us not clutter the output of the cell\n",
    "    from IPython.utils import io\n",
    "    \n",
    "    # Return previously downloaded dataframes\n",
    "    dataframe_file = f\"dataframes/{country_code.lower()}.pickle\"\n",
    "    if os.path.isfile(dataframe_file):\n",
    "        print(f\"Skipping download, a dataframe was already found for {country_code}.\")\n",
    "        return pd.read_pickle(dataframe_file)\n",
    "    \n",
    "    # Use a cache for this country\n",
    "    cache_file = f\"caches/{country_code.lower()}\"\n",
    "    requests_cache.install_cache(cache_file)\n",
    "    \n",
    "    # This will do the heavy lifting\n",
    "    client = EntsoePandasClient(\n",
    "        api_key=os.environ[\"API_TOKEN\"],\n",
    "        session=None,\n",
    "        retry_count=3,\n",
    "        retry_delay=0,\n",
    "        proxies=None,\n",
    "    )\n",
    "    \n",
    "    # Create monthly blocks so we can have a nice progressbar the\n",
    "    # increments with each month. The requests will still be made\n",
    "    # on a daily basis by the entsoe library, as required by the\n",
    "    # ENTSO-E API.\n",
    "    month_intervals = list(entsoe.misc.month_blocks(start, end))\n",
    "    \n",
    "    # Start scraping using the entsoe library acting as a helper\n",
    "    # python API to communicate with the ENTSO-E API.\n",
    "    dfs = []\n",
    "    for month_start_datetime, month_end_datetime in tqdm(month_intervals, desc=country_code):\n",
    "        with io.capture_output() as captured_output:\n",
    "            print(f\"Scraping month: {month_start_datetime.year}-{month_start_datetime.month:02d}\")\n",
    "            dfs.append(\n",
    "                client.query_generation_per_plant(\n",
    "                    country_code,\n",
    "                    start=month_start_datetime,\n",
    "                    end=month_end_datetime,\n",
    "                )\n",
    "            )\n",
    "    \n",
    "    # Combine the scraped monthly dataframes into one large\n",
    "    df = pd.concat(dfs)\n",
    "    \n",
    "    # Save the combined dataframe to disk as a pickle file\n",
    "    # NOTE: the pickle file for Sweden was 19 MB, while the\n",
    "    # request cache was 335 MB.\n",
    "    df.to_pickle(dataframe_file)\n",
    "    \n",
    "    # return the dataframe\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b40f8b8b45e44d9ae40816ef921afb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Countries', max=42, style=ProgressStyle(description_width='inâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2c097e683144da7974054c7528167b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='AL', max=59, style=ProgressStyle(description_width='initial')â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# NOTE: the ENTSO-E API doesn't have data before 2015\n",
    "# NOTE: I think the API is pretty much hardcoded for use with the\n",
    "# Europe/Brussels timezone. There could be daylight savings time\n",
    "# matters that can mess with an hour of data or two during the year.\n",
    "api_data_start = pd.Timestamp(year=2015, month=1,  day=1,  tz='Europe/Brussels')\n",
    "api_data_end   = pd.Timestamp(year=2019, month=11, day=15, tz='Europe/Brussels')\n",
    "\n",
    "# Iterate over the 42 domains (countries mostly), and get their data\n",
    "for country_code in tqdm(DOMAIN_MAPPINGS, desc=\"Countries\"):\n",
    "    get_country_data(country_code, api_data_start, api_data_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
